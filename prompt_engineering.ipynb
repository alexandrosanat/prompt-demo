{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da3aae",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade openai\n",
    "!pip install jupyter-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a675bd",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba01b5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <div style=\"flex: 1;\">\n",
    "    <img src=\"images/notebook.gif\" alt=\"segment\" width=\"500\">\n",
    "  </div>\n",
    "  <div style=\"flex: 1;\">\n",
    "    <h2> Practical Prompt Engineering </h2>\n",
    "    <br>\n",
    "    <div>\n",
    "       In this tutorial, you‚Äôll learn how to:\n",
    "       <ul>\n",
    "        <li>Apply prompt engineering techniques to practical, real-world examples\n",
    "        <li>Tap into the power of roles in messages to go beyond using singular role prompts\n",
    "        <li>Use numbered steps, delimiters, few-shot prompting and other techniques to improve your results\n",
    "        <li>Understand and use chain-of-thought prompting to add more context\n",
    "      </ul>\n",
    "    <div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c8c049",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "‚ö†Ô∏è You can follow along by opening this notebook on google collab.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a82fc7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First let's import all the libraries we're going to use..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "443b222a-e27f-4aca-8fb5-7588ea7d3ab4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc56268",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b099b72",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and retrieve our OpenAI API key..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "767f9581",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# openai.api_key = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67e826",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Chat completion API [documentation](https://platform.openai.com/docs/guides/gpt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "39f7e58b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3898b7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Tip: </b>The 3 types of roles you can use are: <br>\n",
    "\n",
    "<ul>\n",
    "<li> <b>System role:</b> Allows you to specify the way the model answers questions. <br>\n",
    "    Typically we can use it to determine what <b>role</b> the AI should play and how it should behave generally. <br> \n",
    "\n",
    "<li> <b>User role:</b> Equivalent to the queries made by the user\n",
    "\n",
    "<li> <b>Assistant role:</b> The model‚Äôs responses\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65185ef9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Chat completions [response](https://platform.openai.com/docs/guides/gpt/chat-completions-response-format) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5256729d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "response = {\n",
    "    \"choices\": [\n",
    "        {\n",
    "            \"finish_reason\": \"stop\",\n",
    "            \"index\": 0,\n",
    "            \"message\": {\n",
    "                \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\",\n",
    "                \"role\": \"assistant\",\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    \"created\": 1677664795,\n",
    "    \"id\": \"chatcmpl-7QyqpwdfhqwajicIEznoc6Q47XAyW\",\n",
    "    \"model\": \"gpt-3.5-turbo-0613\",\n",
    "    \"object\": \"chat.completion\",\n",
    "    \"usage\": {\"completion_tokens\": 17, \"prompt_tokens\": 57, \"total_tokens\": 74},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf633e0f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The assistant‚Äôs reply can be extracted with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9c7f8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686cb1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The next function allows us to send prompts to the model and get a response back. <br>\n",
    "\n",
    "We have specified the following model parameters:\n",
    "* Model: **GPT-3.5-turbo**\n",
    "* Temperature: **0**\n",
    "\n",
    "The function takes as inputs <u>prompt</u> and a <u>list of previous messages</u>, and returns a new list of messsages that include the prompt and the response from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "779b08c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_completion_from_messages(\n",
    "    prompt, messages, model=\"gpt-3.5-turbo\", temperature=0\n",
    "):\n",
    "    if not isinstance(messages, list):\n",
    "        messages = [messages]\n",
    "\n",
    "    messages.append(prompt)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model, messages=messages, temperature=temperature\n",
    "    )\n",
    "\n",
    "    message = response.choices[0][\"message\"]\n",
    "\n",
    "    print(message[\"content\"])\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2a7b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8ae36d06",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Alex.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"My name is Alex\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Nice to meet you, Alex! How can I assist you today?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = {\"role\": \"user\", \"content\": \"What is my name?\"}\n",
    "\n",
    "response = get_completion_from_messages(prompt, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d007a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ways to Engineer your Prompts ‚öôÔ∏è\n",
    "\n",
    "We will now look at a few different examples of how you can improve your promtps to become the utlimate prompt engineer!\n",
    "\n",
    "Let's explore the following techniques:\n",
    "\n",
    "<ul>\n",
    "<li> <b>Zero-shot prompting</b> \n",
    "<li> <b>Role prompting</b> \n",
    "<li> <b>Detail & Specificity</b> \n",
    "<li> <b>Few-shot prompting</b> \n",
    "<li> <b>Using delimiters</b> \n",
    "<li> <b>Chain-of-thought prompting (CoT)</b> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a618ddd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Zero-shot prompting üí¨\n",
    "\n",
    "First, we have a list of reviews written below. Our task is to summarise them using ChatGPT. <br> Let's see what we can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f516f20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    (\n",
    "        \"Date: December 15, 2021; Username: John123; Review: I am absolutely delighted \\\n",
    "    with this savings product! The interest rates are fantastic, and it has helped \\\n",
    "    me grow my savings significantly. Highly recommend!\"\n",
    "    ),\n",
    "    (\n",
    "        \"Date: November 28, 2021; Username: Sarah77; Review: I must say, I am quite \\\n",
    "    disappointed with this savings product. The promised returns were not as \\\n",
    "    impressive as advertised, and the fees associated with it added up quickly. \\\n",
    "    Not worth it.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Date: January 5, 2022; Username: AlexSmith; Review: My opinion? I'm rather \\\n",
    "    indifferent about this savings product. It's just like any other basic savings \\\n",
    "    account out there. Nothing special, but it does the job.\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ae0dd2ec",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarise these 3 reviews:['Date: December 15, 2021; Username: John123; Review: I am absolutely delighted     with this savings product! The interest rates are fantastic, and it has helped     me grow my savings significantly. Highly recommend!', 'Date: November 28, 2021; Username: Sarah77; Review: I must say, I am quite     disappointed with this savings product. The promised returns were not as     impressive as advertised, and the fees associated with it added up quickly.     Not worth it.', \"Date: January 5, 2022; Username: AlexSmith; Review: My opinion? I'm rather     indifferent about this savings product. It's just like any other basic savings     account out there. Nothing special, but it does the job.\"]\n"
     ]
    }
   ],
   "source": [
    "content = f\"\"\"Summarise these 3 reviews:{reviews}\"\"\"\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0460cb24",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1: John123 is extremely satisfied with the savings product, praising the fantastic interest rates and significant growth of their savings. Highly recommends it.\n",
      "\n",
      "Review 2: Sarah77 is disappointed with the savings product, as the promised returns were not as impressive as advertised and the associated fees accumulated quickly. Considers it not worth it.\n",
      "\n",
      "Review 3: AlexSmith expresses indifference towards the savings product, considering it similar to any other basic savings account. It is deemed as nothing special but gets the job done.\n"
     ]
    }
   ],
   "source": [
    "prompt = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": content,\n",
    "}\n",
    "\n",
    "messages = get_completion_from_messages(prompt, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc7c27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Great! It provided a summary of each review.\n",
    "\n",
    "What we just did is call **zero-shot prompting**, which is just a fancy way of saying that you‚Äôre asking a normal question or simply describing a task.\n",
    "\n",
    "But it's safe to say this is by no means useful enough to be a product yet. \n",
    "\n",
    "Let's now dive into the other prompt engineering techniques to improve our results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab083500",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Role Prompting ü§ñ\n",
    "\n",
    "In the next example we are setting the **role** of the model via the system message. \n",
    "\n",
    "This is known as \"Role Prompting\", and is a general practice to help set the tone and context for the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5a0dbcd1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"\"\"\n",
    "        You are a Review Summariser.\n",
    "        Your job is to process reviews from customers,\n",
    "        and summarise them for analysis for the customer review team.\n",
    "        \"\"\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "messages = [system_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5b46974f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1: John123 is extremely satisfied with the savings product. They highlight the fantastic interest rates and how it has significantly helped them grow their savings. They highly recommend it.\n",
      "\n",
      "Review 2: Sarah77 is disappointed with the savings product. They mention that the promised returns were not as impressive as advertised and the associated fees added up quickly. They believe it is not worth it.\n",
      "\n",
      "Review 3: AlexSmith is indifferent about the savings product. They state that it is just like any other basic savings account and nothing special. However, they mention that it does the job.\n",
      "\n",
      "Overall, the reviews are mixed. While John123 highly recommends the product, Sarah77 is disappointed with it. AlexSmith is neutral and finds it to be an average savings account.\n"
     ]
    }
   ],
   "source": [
    "prompt = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": content,\n",
    "}\n",
    "\n",
    "messages = get_completion_from_messages(prompt, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f2906",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "‚ö†Ô∏è By using a role prompt via the system message, the summary is more structured and much clearer to read for the user.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03f3c21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Detail and Specificity üîç\n",
    "\n",
    "It is important that when you prompt, you are specific and as clear as possible.\n",
    "\n",
    "Note that clear ‚â† short: the more detail you add, the better the model will understand how you want it to behave.\n",
    "\n",
    "In the next example, we'll try to add a category for each review: positive, neutral or negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "81917b99",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1: Positive\n",
      "Review 2: Bad\n",
      "Review 3: Neutral\n"
     ]
    }
   ],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "    You are a Review Summariser. \\\n",
    "    Your job is to process reviews from customers, \\\n",
    "    and summarise them for analysis for the customer review team.\n",
    "    Categorise each review as positive, neutral, or bad.\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "prompt = {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "messages = [system_message]\n",
    "messages = get_completion_from_messages(prompt, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c516f324",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As you can see, the model has only output the categories, and we're now missing all the other information. \n",
    "\n",
    "Let's be a bit more specific:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "332a817f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1:\n",
      "- Name: John123\n",
      "- Date: December 15, 2021\n",
      "- Sentiment: Positive\n",
      "- Summary: John123 is delighted with the savings product, praising the fantastic interest rates and significant growth of savings.\n",
      "\n",
      "Review 2:\n",
      "- Name: Sarah77\n",
      "- Date: November 28, 2021\n",
      "- Sentiment: Negative\n",
      "- Summary: Sarah77 is disappointed with the savings product, mentioning that the promised returns were not as impressive as advertised and the associated fees added up quickly.\n",
      "\n",
      "Review 3:\n",
      "- Name: AlexSmith\n",
      "- Date: January 5, 2022\n",
      "- Sentiment: Neutral\n",
      "- Summary: AlexSmith is indifferent about the savings product, stating that it is similar to any other basic savings account and nothing special, but it gets the job done.\n"
     ]
    }
   ],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "    You are a Review Summariser. Your job is to process reviews \n",
    "    from customers and summarise them for analysis for the customer review team.\n",
    "\n",
    "    For each review output the name and date. \n",
    "    Also label each review as either 'Positive','Neutral', or 'Negative'.\n",
    "    Then provide a summary of key points in a single sentence.\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "prompt = {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "messages = [system_message]\n",
    "messages = get_completion_from_messages(prompt, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54d142",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Great! We now have all the information displayed appropriately for each review. \n",
    "\n",
    "It's even structured the data for us in a list! \n",
    "\n",
    "Let's see if we can further increase out specificity by numbering the steps as well as specifying the format that we want the model to use for our output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "624b23df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "    You are a Review Summariser. Your job is to process reviews \n",
    "    from customers and summarise them for analysis for the customer review team:\n",
    "\n",
    "    1. For each review output the name and date. \n",
    "    2. Also label each review as either 'Positive','Neutral', or 'Negative'.\n",
    "    3. Provide a summary of key points in a single sentence.\n",
    "\n",
    "    Output: When outputting this information, use the following structure:\n",
    "    - [Username]: name of customer who made review\n",
    "    - [Date]: date of review, written as dd/mm/yyyy\n",
    "    - [Sentiment]: review sentiment\n",
    "    - [Key points]: key points of each review in one\n",
    "    \"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "367a5731",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"reviews\": [\n",
      "    {\n",
      "      \"name\": \"John123\",\n",
      "      \"date\": \"December 15, 2021\",\n",
      "      \"sentiment\": \"Positive\",\n",
      "      \"summary\": \"Delighted with the savings product, fantastic interest rates, highly recommend.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Sarah77\",\n",
      "      \"date\": \"November 28, 2021\",\n",
      "      \"sentiment\": \"Negative\",\n",
      "      \"summary\": \"Disappointed with the savings product, returns not as advertised, high fees.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"AlexSmith\",\n",
      "      \"date\": \"January 5, 2022\",\n",
      "      \"sentiment\": \"Neutral\",\n",
      "      \"summary\": \"Indifferent about the savings product, similar to other basic savings accounts.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "content = f\"\"\"Summarise these 3 reviews:{reviews} and return your response as a JSON\"\"\"\n",
    "\n",
    "prompt = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": content,\n",
    "}\n",
    "\n",
    "messages = [system_message]\n",
    "messages = get_completion_from_messages(prompt, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe53404",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As you can see, we get the output in JSON format. \n",
    "\n",
    "This is quite powerful: when we structure our output as we have done in the previous section, the model can easily convert this into a structured format as shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b195c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Few-shot prompting üìÑ\n",
    "\n",
    "Few-shot prompting is a prompt engineering technique where you provide example tasks and their expected outputs in your prompt. \n",
    "\n",
    "So, instead of just describing the task you also provide examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9f404bd4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "    You are a Review Summariser. Your job is to process reviews \n",
    "    from customers and summarise them for analysis for the customer review team.\n",
    "\n",
    "    For each review output the name and date. \n",
    "    Also label each review as either 'Positive','Neutral', or 'Negative'.\n",
    "    Then provide a summary of key points in a single sentence.\n",
    "    \n",
    "    Example 1:\n",
    "    \"Date: April 1, 2022\\nUsername: JaneDoe\\nReview: I'm really not happy with this savings product. \\\n",
    "    The interest rates are lower than promised and the customer service is lacking. I wouldn't recommend it.\",\n",
    "\n",
    "    Output 1:\n",
    "    - username: \"JaneDoe\"\n",
    "    - review_date: \"01/04/2022\"\n",
    "    - sentiment: \"negative\"\n",
    "    - key_points: \"Lower interest rates than promised, lacking customer service\"\n",
    "    - summary: JaneDoe is unhappy with the savings product, stating that the interest \\\n",
    "    rates are lower than promised and the customer service is lacking.\n",
    "    \"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "35451375",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- username: \"John123\"\n",
      "- review_date: \"15/12/2021\"\n",
      "- sentiment: \"positive\"\n",
      "- key_points: \"Fantastic interest rates, significant savings growth\"\n",
      "- summary: John123 is delighted with the savings product, praising the fantastic interest rates and significant savings growth.\n",
      "\n",
      "- username: \"Sarah77\"\n",
      "- review_date: \"28/11/2021\"\n",
      "- sentiment: \"negative\"\n",
      "- key_points: \"Disappointing returns, high fees\"\n",
      "- summary: Sarah77 is disappointed with the savings product, expressing dissatisfaction with the returns not meeting expectations and the accumulation of high fees.\n",
      "\n",
      "- username: \"AlexSmith\"\n",
      "- review_date: \"05/01/2022\"\n",
      "- sentiment: \"neutral\"\n",
      "- key_points: \"Indifferent, basic savings account\"\n",
      "- summary: AlexSmith is indifferent about the savings product, describing it as a basic savings account without any standout features.\n"
     ]
    }
   ],
   "source": [
    "content = f\"\"\"Summarise these 3 reviews:{reviews}\"\"\"\n",
    "\n",
    "prompt = {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "messages = [system_message]\n",
    "messages = get_completion_from_messages(prompt, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a652c4b7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "‚ö†Ô∏è By using a few-shot prompting, the model included the 'key_points' in its answer but also adopted our preferred way of writing the summary.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f301c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Using Delimiters üîñ\n",
    "\n",
    "Delimiters can help to separate the content and examples from the task description. They can also make it possible to refer to specific parts of your prompt at a later point in the prompt. A delimiter can be any sequence of characters that usually wouldn‚Äôt appear together, for example:\n",
    "\n",
    "* \\>>>>>\n",
    "* \\====\n",
    "* \\####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f63157",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The number of characters that you use doesn‚Äôt matter too much, as long as you make sure that the sequence is relatively unique, otherwise this might confuse the model. Additionally, you can add labels just before or just after the delimiters:\n",
    "\n",
    "* START CONTENT>>>>> content <<<<<END CONTENT\n",
    "* \\==== START content END ====\n",
    "* \\#### START EXAMPLES examples #### END EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "64b51444",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "    You are a Review Summariser. Your job is to process reviews \n",
    "    from customers and summarise them for analysis for the customer review team.\n",
    "\n",
    "    For each review output the name and date. \n",
    "    Also label each review as either 'Positive','Neutral', or 'Negative'.\n",
    "    Then provide a summary of key points in a single sentence.\n",
    "    \n",
    "    #### START EXAMPLES ####\n",
    "\n",
    "    ------ Example Inputs ------\n",
    "    \"Date: April 1, 2022\\nUsername: JaneDoe\\nReview: I'm really not happy with this savings product. \\\n",
    "    The interest rates are lower than promised and the customer service is lacking. I wouldn't recommend it.\",\n",
    "\n",
    "    ------ Example Outputs ------\n",
    "    - username: \"JaneDoe\"\n",
    "    - review_date: \"01/04/2022\"\n",
    "    - sentiment: \"negative\"\n",
    "    - key_points: \"Lower interest rates than promised, lacking customer service\"\n",
    "    - summary: JaneDoe is unhappy with the savings product, stating that the interest \\\n",
    "    rates are lower than promised and the customer service is lacking.\n",
    "    \n",
    "    #### END EXAMPLES ####\n",
    "\n",
    "    \"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "27aa647c",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- username: \"John123\"\n",
      "  - review_date: \"15/12/2021\"\n",
      "  - sentiment: \"positive\"\n",
      "  - key_points: \"Fantastic interest rates, helped grow savings significantly\"\n",
      "  - summary: John123 is delighted with the savings product, praising the fantastic interest rates and how it has significantly helped grow their savings.\n",
      "\n",
      "- username: \"Sarah77\"\n",
      "  - review_date: \"28/11/2021\"\n",
      "  - sentiment: \"negative\"\n",
      "  - key_points: \"Promised returns not as impressive as advertised, fees added up quickly\"\n",
      "  - summary: Sarah77 is disappointed with the savings product, expressing that the promised returns were not as impressive as advertised and the fees associated with it added up quickly.\n",
      "\n",
      "- username: \"AlexSmith\"\n",
      "  - review_date: \"05/01/2022\"\n",
      "  - sentiment: \"neutral\"\n",
      "  - key_points: \"Indifferent, just like any other basic savings account\"\n",
      "  - summary: AlexSmith is indifferent about the savings product, stating that it is just like any other basic savings account out there and nothing special, but it does the job.\n"
     ]
    }
   ],
   "source": [
    "content = f\"\"\"Summarise these 3 reviews:{reviews}\"\"\"\n",
    "\n",
    "prompt = {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "messages = [system_message]\n",
    "messages = get_completion_from_messages(prompt, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9037411f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chain-of-thought prompting (CoT) üí≠\n",
    "\n",
    "To apply CoT, you prompt the model to generate intermediate results that then become part of the prompt in a second request. The increased context makes it more likely that the model will arrive at a useful output.\n",
    "\n",
    "The smallest form of CoT prompting is **zero-shot CoT**, where you literally ask the model to *think step by step*. <br> This approach yields impressive results for mathematical tasks that LLMs otherwise often solve incorrectly.\n",
    "\n",
    "More commonly, chain-of-thought operations are technically split into two stages:\n",
    "\n",
    "- *Reasoning extraction*, where the model generates the increased context\n",
    "- *Answer extraction*, where the model uses the increased context to generate the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c6000",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Zero-shot CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "3f170d07",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Bought 10 apples.\n",
      "Step 2: Gave 2 apples to the neighbor. Remaining: 10 - 2 = 8 apples.\n",
      "Step 3: Gave 2 apples to the repairman. Remaining: 8 - 2 = 6 apples.\n",
      "Step 4: Bought 5 more apples. Total: 6 + 5 = 11 apples.\n",
      "Step 5: Ate 1 apple. Remaining: 11 - 1 = 10 apples.\n",
      "\n",
      "Therefore, you remained with 10 apples.\n"
     ]
    }
   ],
   "source": [
    "content = f\"\"\"\n",
    "I went to the market and bought 10 apples.\n",
    "I gave 2 apples to the neighbor and 2 to the repairman.\n",
    "I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n",
    "Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "prompt = {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "messages = []\n",
    "messages = get_completion_from_messages(prompt, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dc78ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary üî•\n",
    "\n",
    "We have looked at all the main different techniques that you can use to engineer your prompts! \n",
    "\n",
    "<ul>\n",
    "<li> <b>Zero-shot prompting:</b> Asking the language model a normal question without any additional context\n",
    "<li> <b>Role prompting:</b> Specifying how the model will answer the questions\n",
    "<li> <b>Detail & Specificity:</b> Breaking down a complex prompt into a series of small, specific steps\n",
    "<li> <b>Few-shot prompting:</b> Conditioning the model on a few examples to boost its performance\n",
    "<li> <b>Using delimiters:</b> Adding special tokens or phrases to provide structure and instructions to the model\n",
    "<li> <b>Chain-of-thought prompting:</b> Prompt the model to generate intermediate results that then become part of the prompt in a second request\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa4866",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bonus: Chain-of-thought prompting in functions üí•\n",
    "\n",
    "Chain of thought process is a powerful technique that has enabled LLMs to interact with functions and itegrate the provided context into their answers.\n",
    "\n",
    "Let's try to demonstrate this by answering the following question:\n",
    "\n",
    "*What is the weather in Edinburgh?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec6e5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First we need to modify our API call to enable function calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "9b9f0af8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_completion_from_messages_func(\n",
    "    prompt, messages, functions, model=\"gpt-3.5-turbo-0613\", temperature=0\n",
    "):\n",
    "    if not isinstance(messages, list):\n",
    "        messages = [messages]\n",
    "\n",
    "    messages.append(prompt)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    message = response.choices[0][\"message\"]\n",
    "\n",
    "    print(message)\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc9d99",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's define our python API that returns the weather using a location as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "d746e5fe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_current_weather(location):\n",
    "    if location == \"Edinburgh\":\n",
    "        return {\"temperature\": 9, \"unit\": \"celsius\", \"description\": \"Sunny\"}\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470190b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Remember! LLMs can only understand *language* so the only way for our model to have knowledge of this function is if we describe it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "7fb87fb2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The location/city eg. London\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7053c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's now send our question to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "7d2901b3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": \"{\\n  \\\"location\\\": \\\"Edinburgh\\\"\\n}\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "content = f\"\"\"What is the weather in Edinburgh?\"\"\"\n",
    "\n",
    "prompt = {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "messages = []\n",
    "\n",
    "messages = get_completion_from_messages_func(prompt, messages, function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f86240",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First we need to extract the function name and function arguments from the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "5fb29c32",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function_name = messages[-1][\"function_call\"][\"name\"]\n",
    "function_args = json.loads(messages[-1][\"function_call\"][\"arguments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "71edb1fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Name: get_current_weather\n",
      "Function Arguments: {'location': 'Edinburgh'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Function Name:\", function_name)\n",
    "print(\"Function Arguments:\", function_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82dab20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's now call our actual python function to get the response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "6e579f1b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temperature': 9, 'unit': 'celsius', 'description': 'Sunny'}\n"
     ]
    }
   ],
   "source": [
    "function_response = eval(function_name)(**function_args)\n",
    "\n",
    "print(function_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6778b5e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Note:**\n",
    "\n",
    "This: ```eval(function_name)(**function_args)```\n",
    "\n",
    "is equivalent to this: ```get_current_weather(location='Edinburgh')```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36ac939",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Tip: </b>There is actually only more role that can be used with ONLY gpt-3.5-turbo-0613 and gpt-4-0613. <br>\n",
    "\n",
    "<ul>\n",
    "<li> <b>Function role:</b> Allows you to specify the response of a function that the model can use to answer the original question.\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "0d08a16f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "new_message = {\n",
    "    \"role\": \"function\",\n",
    "    \"name\": function_name,\n",
    "    \"content\": str(function_response),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43feb746",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's finally get the response from our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "437391d6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"The current weather in Edinburgh is sunny with a temperature of 9 degrees Celsius.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = get_completion_from_messages_func(new_message, messages, function)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
